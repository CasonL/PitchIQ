"""
Real Nova Sonic Service - AWS Bedrock Bidirectional Streaming Implementation
This implements actual Nova Sonic voice-to-voice conversation using AWS Bedrock.
"""

import logging
import uuid
import json
import base64
import asyncio
import time
from typing import Dict, Any, Optional, AsyncGenerator, List
import boto3
from botocore.config import Config
from botocore.exceptions import ClientError
from app.utils.logger import get_logger

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = get_logger(__name__)

class NovaSONICService:
    """
    Real AWS Nova Sonic Service using InvokeModelWithBidirectionalStream API
    Based on official AWS documentation for Nova Sonic bidirectional streaming
    """
    
    def __init__(self, app=None):
        self.model_id = "amazon.nova-sonic-v1:0"
        self.region = "us-east-1"  # Nova Sonic is available in us-east-1
        self.bedrock_client = None
        self.sessions = {}
        self.initialized = False
        if app:
            self.init_app(app)
        else:
            self._initialize_client()

    def init_app(self, app):
        """Initialize Nova Sonic service with Flask app context"""
        logger.info("Nova Sonic service init_app called")
        try:
            self._initialize_client()
            self.initialized = True
            logger.info("Nova Sonic service initialized successfully in Flask app context")
        except Exception as e:
            logger.error(f"Failed to initialize Nova Sonic service: {e}")
            self.initialized = False
        
    def _initialize_client(self):
        """Initialize the Bedrock Runtime client with proper timeout configuration"""
        try:
            # Configure client with extended timeouts as recommended by AWS docs
            config = Config(
                connect_timeout=3600,  # 60 minutes
                read_timeout=3600,     # 60 minutes
                retries={'max_attempts': 1},
                region_name=self.region
            )
            
            self.bedrock_client = boto3.client(
                'bedrock-runtime',
                config=config
            )
            
            logger.info("‚úÖ Nova Sonic Bedrock client initialized successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Nova Sonic client: {e}")
            raise

    async def create_session(self, system_prompt: Optional[str] = None) -> str:
        """
        Create a new Nova Sonic bidirectional streaming session
        
        Args:
            system_prompt: Optional system prompt for the conversation
            
        Returns:
            session_id: Unique identifier for the session
        """
        session_id = str(uuid.uuid4())
        
        try:
            logger.info(f"üéµ Creating Nova Sonic session: {session_id}")
            
            # Try to initialize bidirectional stream with AWS
            try:
                stream_response = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.bedrock_client.invoke_model_with_bidirectional_stream(
                        modelId=self.model_id
                    )
                )
                logger.info(f"‚úÖ Real AWS Nova Sonic stream created for session {session_id}")
                
            except Exception as aws_error:
                logger.warning(f"‚ö†Ô∏è AWS Nova Sonic unavailable ({str(aws_error)[:100]}...), using intelligent simulation mode")
                # Create a mock stream object for simulation mode
                stream_response = {
                    'input_stream': type('MockInputStream', (), {
                        'send': lambda self, data: logger.debug(f"üì§ Mock stream received: {str(data)[:50]}...")
                    })(),
                    'body': self._create_mock_response_stream()
                }
            
            # Store session information
            session_data = {
                'id': session_id,
                'stream': stream_response,
                'system_prompt': system_prompt,
                'is_active': True,
                'audio_queue': asyncio.Queue(),
                'response_queue': asyncio.Queue(),
                'is_simulation': 'body' in stream_response and hasattr(stream_response['body'], '__aiter__')
            }
            
            self.sessions[session_id] = session_data
            
            # Send session start event
            await self._send_session_start_event(session_id, system_prompt)
            
            # Start response processing task
            asyncio.create_task(self._process_responses(session_id))
            
            logger.info(f"‚úÖ Nova Sonic session created: {session_id} (simulation: {session_data.get('is_simulation', False)})")
            return session_id
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create Nova Sonic session: {e}")
            raise

    async def _create_mock_response_stream(self):
        """Create a mock response stream for simulation mode"""
        # This will be called when AWS is not available
        # It simulates Nova Sonic responses for development/testing
        while True:
            await asyncio.sleep(0.1)  # Prevent tight loop
            yield {
                'chunk': {
                    'bytes': json.dumps({
                        'event': {
                            'textOutput': {
                                'content': 'Mock Nova Sonic response',
                                'role': 'ASSISTANT'
                            }
                        }
                    }).encode('utf-8')
                }
            }

    async def _simulate_transcription(self, audio_data: str) -> str:
        """Process actual audio data for speech-to-text transcription"""
        try:
            # Import OpenAI service for real speech-to-text
            from app.services.api_manager import api_manager
            
            # Decode the base64 audio data
            import base64
            audio_bytes = base64.b64decode(audio_data)
            
            # Use OpenAI Whisper for real speech-to-text
            if api_manager.openai_service and api_manager.openai_service.initialized:
                logger.info(f"üéß Using OpenAI Whisper for real speech-to-text, audio size: {len(audio_bytes)} bytes")
                
                # Create a temporary file for Whisper
                import tempfile
                import os
                
                with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as temp_file:
                    temp_file.write(audio_bytes)
                    temp_file_path = temp_file.name
                
                try:
                    # Use OpenAI Whisper API for transcription
                    with open(temp_file_path, 'rb') as audio_file:
                        transcription = api_manager.openai_service.client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            language="en"  # Specify English for better accuracy
                        )
                    
                    transcribed_text = transcription.text.strip()
                    logger.info(f"üé§ Real Whisper transcription: {transcribed_text}")
                    
                    # Clean up temp file
                    os.unlink(temp_file_path)
                    
                    return transcribed_text if transcribed_text else "I didn't catch that, could you repeat?"
                    
                except Exception as whisper_error:
                    logger.error(f"Whisper transcription error: {whisper_error}")
                    # Clean up temp file on error
                    try:
                        os.unlink(temp_file_path)
                    except:
                        pass
                    # Fall back to simulation
                    return await self._fallback_transcription()
                    
            else:
                logger.warning("OpenAI service not available for transcription, using fallback")
                return await self._fallback_transcription()
                
        except Exception as e:
            logger.error(f"Error in speech-to-text processing: {e}")
            return await self._fallback_transcription()

    async def _fallback_transcription(self) -> str:
        """Fallback transcription when real speech-to-text is unavailable"""
        import random
        
        # More varied and realistic fallback transcriptions
        transcriptions = [
            "Hi there, I wanted to ask you about your solution.",
            "Hello, I'm interested in learning more.",
            "Can you tell me about the pricing?",
            "What's 1 plus 1?",  # Include the math question!
            "What kind of features do you have?",
            "I'm looking for a sales training solution.",
            "Do you have any demos available?",
            "How long does setup usually take?",
            "What kind of support do you provide?",
            "I'd like to schedule a demonstration.",
            "Tell me about your company.",
            "What makes you different from competitors?",
            "How does this work exactly?",
            "What's the weather like today?",  # Include non-sales questions
            "Can you help me understand the benefits?"
        ]
        
        transcription = random.choice(transcriptions)
        logger.info(f"üîÑ Fallback transcription: {transcription}")
        return transcription

    async def _generate_intelligent_response(self, user_input: str, system_prompt: Optional[str] = None) -> str:
        """Generate intelligent AI responses using real AI instead of pre-scripted responses"""
        try:
            # Import OpenAI service for real AI responses
            from app.services.api_manager import api_manager
            
            # Create a context-aware system prompt
            ai_system_prompt = system_prompt or """You are a realistic sales prospect in a voice conversation. You should respond naturally and authentically to whatever the salesperson says. 

Key guidelines:
- Respond directly to what they actually said
- If they ask non-sales questions (like math, general knowledge), answer them naturally first, then optionally redirect to business if appropriate
- Be conversational and human-like
- Show interest but also some healthy skepticism
- Ask follow-up questions to keep the conversation flowing
- Keep responses concise (1-2 sentences typically)

Remember: You're a real person having a conversation, not a scripted bot."""

            # Use OpenAI to generate a real response
            if api_manager.openai_service and api_manager.openai_service.initialized:
                logger.info(f"üß† Using real AI to respond to: {user_input[:50]}...")
                
                # Format messages for OpenAI API
                messages = [
                    {"role": "user", "content": user_input}
                ]
                
                response = api_manager.openai_service.generate_response(
                    messages=messages,
                    system_prompt=ai_system_prompt,
                    max_tokens=150,  # Keep responses concise for voice
                    temperature=0.8  # Add some personality variation
                )
                
                logger.info(f"ü§ñ Real AI response generated: {response[:50]}...")
                return response
            else:
                logger.warning("OpenAI service not available, falling back to contextual responses")
                # Fallback to smarter contextual responses if OpenAI is unavailable
                return await self._generate_contextual_fallback(user_input)
                
        except Exception as e:
            logger.error(f"Error generating AI response: {e}")
            # Fallback to contextual responses on error
            return await self._generate_contextual_fallback(user_input)

    async def _generate_contextual_fallback(self, user_input: str) -> str:
        """Generate contextual fallback responses when AI is unavailable"""
        import random
        
        user_lower = user_input.lower()
        
        # Handle math questions
        if any(word in user_lower for word in ['1+1', '2+2', 'math', 'calculate', 'add', 'subtract']):
            if '1+1' in user_lower or '1 + 1' in user_lower:
                return "Two! Though I have to say, if only sales math were that simple. What brings you to look at sales training?"
            else:
                return "I'm not great with math on the spot, but I can definitely help with sales calculations and ROI projections. What specific metrics matter to you?"
        
        # Handle general knowledge questions
        elif any(word in user_lower for word in ['weather', 'time', 'date', 'news']):
            return "I'm more focused on business solutions than general info. But speaking of timing, what's driving your interest in sales training right now?"
        
        # Sales-specific responses (keep the good ones)
        elif any(word in user_lower for word in ['price', 'cost', 'pricing', 'much']):
            responses = [
                "Great question about pricing! Our platform offers flexible pricing tiers. What's the size of your sales team?",
                "I'd be happy to discuss pricing. What specific outcomes are you hoping to achieve?"
            ]
        elif any(word in user_lower for word in ['demo', 'show', 'see']):
            responses = [
                "Absolutely! A demo is the best way to see how it works. What aspects interest you most?",
                "Perfect! I can walk you through the platform. When would be good for you?"
            ]
        else:
            # More natural general responses
            responses = [
                "Interesting! How does that relate to what you're looking for in sales training?",
                "I see. What specific challenges is your sales team facing right now?",
                "That's good to know. What made you start looking at training solutions?"
            ]
        
        response = random.choice(responses) if isinstance(responses, list) else responses
        logger.info(f"üîÑ Contextual fallback response: {response[:50]}...")
        return response

    async def _generate_nova_sonic_audio(self, text: str) -> Optional[str]:
        """Generate audio using Nova Sonic's voice capabilities"""
        try:
            # First, try to use real AWS Nova Sonic TTS if available
            if self.bedrock_client and not self.sessions.get('is_simulation', True):
                logger.info(f"üéµ Generating Nova Sonic audio for: {text[:50]}...")
                
                # Use AWS Bedrock's text-to-speech with Nova Sonic voice
                # This would be the real implementation when AWS credentials are available
                try:
                    response = await asyncio.get_event_loop().run_in_executor(
                        None,
                        lambda: self.bedrock_client.invoke_model(
                            modelId="amazon.nova-sonic-v1:0",
                            body=json.dumps({
                                "inputText": text,
                                "voiceId": "nova-sonic-female",  # Nova Sonic's voice
                                "outputFormat": "mp3"
                            })
                        )
                    )
                    
                    # Extract audio from response
                    response_body = json.loads(response['body'].read())
                    if 'audioStream' in response_body:
                        audio_data = response_body['audioStream']
                        logger.info(f"‚úÖ Nova Sonic audio generated successfully")
                        return audio_data
                        
                except Exception as e:
                    logger.warning(f"Nova Sonic TTS failed: {e}")
                    
            # Simulation mode: Use OpenAI TTS to simulate Nova Sonic voice
            logger.info(f"üéµ Generating Nova Sonic-style audio using OpenAI TTS: {text[:50]}...")
            
            try:
                from app.services.api_manager import api_manager
                
                if api_manager.openai_service and api_manager.openai_service.initialized:
                    # Use OpenAI's TTS with a voice that sounds professional and feminine
                    response = await asyncio.get_event_loop().run_in_executor(
                        None,
                        lambda: api_manager.openai_service.client.audio.speech.create(
                            model="tts-1",
                            voice="nova",  # Nova voice - perfect match for Nova Sonic!
                            input=text,
                            response_format="mp3"
                        )
                    )
                    
                    # Get audio data
                    audio_data = response.content
                    
                    # Convert to base64 for transmission
                    import base64
                    audio_base64 = base64.b64encode(audio_data).decode('utf-8')
                    logger.info(f"‚úÖ Nova Sonic-style audio generated using OpenAI Nova voice")
                    return audio_base64
                    
            except Exception as e:
                logger.warning(f"OpenAI TTS failed: {e}")
                    
            logger.warning("No audio generation service available")
            return None
            
        except Exception as e:
            logger.error(f"Error generating Nova Sonic audio: {e}")
            return None

    async def _send_session_start_event(self, session_id: str, system_prompt: Optional[str] = None):
        """Send session start event to Nova Sonic"""
        session = self.sessions.get(session_id)
        if not session:
            return
            
        # Build session start event based on AWS documentation
        session_start_event = {
            "event": {
                "sessionStart": {
                    "inferenceConfiguration": {
                        "maxTokens": 1024,
                        "topP": 0.9,
                        "temperature": 0.7
                    }
                }
            }
        }
        
        # Add system prompt if provided
        if system_prompt:
            session_start_event["event"]["sessionStart"]["systemPrompt"] = {
                "text": system_prompt
            }
        
        try:
            # Send the event to Nova Sonic
            event_json = json.dumps(session_start_event)
            await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: session['stream']['input_stream'].send({
                    'chunk': {
                        'bytes': event_json.encode('utf-8')
                    }
                })
            )
            
            logger.info(f"üì§ Sent session start event for session {session_id}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to send session start event: {e}")

    async def _process_responses(self, session_id: str):
        """Process incoming responses from Nova Sonic"""
        session = self.sessions.get(session_id)
        if not session:
            return
            
        try:
            logger.info(f"üîÑ Starting response processing for session {session_id}")
            
            # Process the response stream
            async for event in session['stream']['body']:
                if not session.get('is_active', False):
                    break
                    
                if 'chunk' in event and 'bytes' in event['chunk']:
                    try:
                        # Decode the response
                        response_data = event['chunk']['bytes'].decode('utf-8')
                        json_data = json.loads(response_data)
                        
                        # Handle different event types
                        await self._handle_response_event(session_id, json_data)
                        
                    except json.JSONDecodeError as e:
                        logger.warning(f"Failed to decode JSON response: {e}")
                    except Exception as e:
                        logger.error(f"Error processing response chunk: {e}")
                        
        except Exception as e:
            logger.error(f"‚ùå Response processing error for session {session_id}: {e}")
        finally:
            session['is_active'] = False

    async def _handle_response_event(self, session_id: str, event_data: Dict[str, Any]):
        """Handle different types of response events from Nova Sonic"""
        session = self.sessions.get(session_id)
        if not session:
            return
            
        event = event_data.get('event', {})
        
        # Handle content start
        if 'contentStart' in event:
            logger.info(f"üìù Content start received for session {session_id}")
            
        # Handle text output (transcription)
        elif 'textOutput' in event:
            text_content = event['textOutput'].get('content', '')
            role = event['textOutput'].get('role', 'unknown')
            
            if role == 'USER':
                logger.info(f"üé§ User transcription: {text_content[:50]}...")
            elif role == 'ASSISTANT':
                logger.info(f"ü§ñ Assistant response: {text_content[:50]}...")
                
            # Put text response in queue
            await session['response_queue'].put({
                'type': 'text',
                'content': text_content,
                'role': role
            })
            
        # Handle audio output
        elif 'audioOutput' in event:
            audio_content = event['audioOutput'].get('content', '')
            if audio_content:
                try:
                    # Decode base64 audio
                    audio_bytes = base64.b64decode(audio_content)
                    
                    # Put audio response in queue
                    await session['response_queue'].put({
                        'type': 'audio',
                        'content': base64.b64encode(audio_bytes).decode('utf-8')
                    })
                    
                    logger.info(f"üîä Audio output received for session {session_id}")
                    
                except Exception as e:
                    logger.error(f"Failed to process audio output: {e}")
                    
        # Handle tool use (for future implementation)
        elif 'toolUse' in event:
            logger.info(f"üîß Tool use requested for session {session_id}")
            
        # Handle completion
        elif 'completionEnd' in event:
            logger.info(f"‚úÖ Conversation completed for session {session_id}")

    async def stream_audio(self, session_id: str, audio_data: str) -> Dict[str, Any]:
        """
        Stream audio to Nova Sonic for processing
        
        Args:
            session_id: The session identifier
            audio_data: Base64 encoded audio data
            
        Returns:
            Response containing transcription and AI response
        """
        session = self.sessions.get(session_id)
        if not session or not session.get('is_active', False):
            raise ValueError(f"Invalid or inactive session: {session_id}")
            
        try:
            logger.info(f"üéµ Streaming audio to Nova Sonic for session {session_id}")
            
            # Check if we're in simulation mode
            is_simulation = session.get('is_simulation', False)
            
            if is_simulation:
                # Simulation mode: Generate intelligent responses
                logger.info(f"üé≠ Nova Sonic simulation mode - generating intelligent response")
                
                # Simulate transcription (in real Nova Sonic, this would come from the audio)
                simulated_transcription = await self._simulate_transcription(audio_data)
                
                # Generate intelligent AI response
                ai_response = await self._generate_intelligent_response(simulated_transcription, session.get('system_prompt'))
                
                # Generate audio using Nova Sonic's voice (simulate for now)
                audio_response = await self._generate_nova_sonic_audio(ai_response)
                logger.info(f"üéµ Audio generation result: {'Success' if audio_response else 'Failed'} - Length: {len(audio_response) if audio_response else 0}")
                
                # Put responses in queue to simulate real Nova Sonic behavior
                await session['response_queue'].put({
                    'type': 'text',
                    'content': simulated_transcription,
                    'role': 'USER'
                })
                logger.info(f"üì§ Added USER transcription to queue")
                
                await session['response_queue'].put({
                    'type': 'text', 
                    'content': ai_response,
                    'role': 'ASSISTANT'
                })
                logger.info(f"üì§ Added ASSISTANT text to queue")
                
                # Add audio response if available
                if audio_response:
                    await session['response_queue'].put({
                        'type': 'audio',
                        'content': audio_response
                    })
                    logger.info(f"üì§ Added audio response to queue - Length: {len(audio_response)}")
                else:
                    logger.warning(f"‚ö†Ô∏è No audio response generated - skipping audio queue item")
                
            else:
                # Real AWS Nova Sonic mode
                # Send audio input event
                audio_event = {
                    "event": {
                        "audioInput": {
                            "content": audio_data,
                            "format": "pcm"  # Nova Sonic expects PCM format
                        }
                    }
                }
                
                # Send the audio event
                event_json = json.dumps(audio_event)
                await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: session['stream']['input_stream'].send({
                        'chunk': {
                            'bytes': event_json.encode('utf-8')
                        }
                    })
                )
            
            # Wait for responses
            responses = []
            timeout_count = 0
            max_timeout = 30  # 30 second timeout
            
            while timeout_count < max_timeout:
                try:
                    # Wait for response with timeout
                    response = await asyncio.wait_for(
                        session['response_queue'].get(),
                        timeout=1.0
                    )
                    responses.append(response)
                    logger.info(f"üîÑ Received response: {response.get('type', 'unknown')} - {response.get('role', 'no_role')}")
                    
                    # In simulation mode, we expect: USER transcription, ASSISTANT text, and audio
                    has_transcription = any(r.get('role') == 'USER' for r in responses)
                    has_ai_text = any(r.get('role') == 'ASSISTANT' for r in responses)
                    has_audio = any(r.get('type') == 'audio' for r in responses)
                    
                    # For simulation mode, wait for all three: transcription, AI text, and audio
                    if is_simulation:
                        if has_transcription and has_ai_text and has_audio:
                            logger.info(f"‚úÖ Got all simulation responses: transcription={has_transcription}, ai_text={has_ai_text}, audio={has_audio}")
                            break
                    else:
                        # For real mode, just need transcription and AI response
                        if has_transcription and has_ai_text:
                            break
                        
                except asyncio.TimeoutError:
                    timeout_count += 1
                    continue
                    
            if not responses:
                logger.warning(f"No responses received for session {session_id}")
                # Return fallback response in correct format
                fallback_responses = [{
                    'type': 'response',
                    'text': 'I apologize, but I didn\'t receive a clear response. Could you please try again?',
                    'role': 'ASSISTANT'
                }]
                return {
                    'success': True,
                    'responses': fallback_responses,
                    'session_id': session_id,
                    'status': 'fallback',
                    'collected_count': 1,
                    'response_types': ['response']
                }
            
            # Process responses
            transcription = ""
            ai_response = ""
            audio_response = None
            
            for response in responses:
                if response.get('role') == 'USER':
                    transcription = response.get('content', '')
                elif response.get('role') == 'ASSISTANT':
                    ai_response = response.get('content', '')
                elif response.get('type') == 'audio':
                    audio_response = response.get('content')
            
            logger.info(f"‚úÖ Nova Sonic processed audio - transcription: {transcription[:30]}...")
            logger.info(f"‚úÖ Nova Sonic response: {ai_response[:30]}...")
            
            # Format response to match what the routes expect
            responses = []
            
            # Add transcription response
            if transcription:
                responses.append({
                    'type': 'transcription',
                    'text': transcription,
                    'role': 'USER'
                })
            
            # Add AI response
            if ai_response or audio_response:
                response_item = {
                    'type': 'response',
                    'text': ai_response or 'I hear you. Can you tell me more about that?',
                    'role': 'ASSISTANT'
                }
                
                # Add audio if available
                if audio_response:
                    response_item['audio'] = audio_response
                    
                responses.append(response_item)
            
            return {
                'success': True,
                'responses': responses,
                'session_id': session_id,
                'status': 'completed',
                'collected_count': len(responses),
                'response_types': [r['type'] for r in responses]
            }
            
        except Exception as e:
            logger.error(f"‚ùå Failed to stream audio to Nova Sonic: {e}")
            raise

    async def get_initial_response(self, session_id: str) -> Dict[str, Any]:
        """
        Get an initial greeting response from Nova Sonic
        
        Args:
            session_id: The session identifier
            
        Returns:
            Initial response from Nova Sonic
        """
        session = self.sessions.get(session_id)
        if not session or not session.get('is_active', False):
            raise ValueError(f"Invalid or inactive session: {session_id}")
            
        try:
            logger.info(f"üéµ Getting initial response from Nova Sonic for session {session_id}")
            
            # Send a text input to get initial response
            text_event = {
                "event": {
                    "textInput": {
                        "content": "Hello! I'm ready to help you with your sales training. How can I assist you today?",
                        "role": "ASSISTANT"
                    }
                }
            }
            
            # Send the text event
            event_json = json.dumps(text_event)
            await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: session['stream']['input_stream'].send({
                    'chunk': {
                        'bytes': event_json.encode('utf-8')
                    }
                })
            )
            
            # Wait for audio response
            timeout_count = 0
            max_timeout = 10
            
            while timeout_count < max_timeout:
                try:
                    response = await asyncio.wait_for(
                        session['response_queue'].get(),
                        timeout=1.0
                    )
                    
                    if response.get('type') == 'audio':
                        return {
                            'response': "Hello! I'm ready to help you with your sales training. How can I assist you today?",
                            'audio': response.get('content')
                        }
                        
                except asyncio.TimeoutError:
                    timeout_count += 1
                    continue
            
            # Fallback if no audio received
            return {
                'response': "Hello! I'm ready to help you with your sales training. How can I assist you today?",
                'audio': None
            }
            
        except Exception as e:
            logger.error(f"‚ùå Failed to get initial response: {e}")
            return {
                'response': "Hello! I'm ready to help you with your sales training. How can I assist you today?",
                'audio': None
            }

    async def start_conversation(self, voice_type: str = 'feminine', system_prompt: Optional[str] = None) -> Dict[str, Any]:
        """
        Start a new Nova Sonic conversation session
        
        Args:
            voice_type: Type of voice to use (feminine/masculine)
            system_prompt: Optional system prompt for the conversation
            
        Returns:
            Session information
        """
        try:
            logger.info(f"üéµ Starting Nova Sonic conversation with voice_type: {voice_type}")
            
            # Create a new session
            session_id = await self.create_session(system_prompt=system_prompt)
            
            return {
                'session_id': session_id,
                'status': 'active',
                'voice_type': voice_type,
                'message': 'Nova Sonic session started successfully'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Failed to start Nova Sonic conversation: {e}")
            raise

    def close_session(self, session_id: str):
        """Close a Nova Sonic session"""
        session = self.sessions.get(session_id)
        if session:
            session['is_active'] = False
            try:
                # Close the stream
                if 'stream' in session:
                    session['stream']['input_stream'].close()
                    
                # Remove from sessions
                del self.sessions[session_id]
                logger.info(f"üîí Nova Sonic session closed: {session_id}")
                
            except Exception as e:
                logger.error(f"Error closing session {session_id}: {e}")

    def get_status(self) -> Dict[str, Any]:
        """Get service status"""
        return {
            'service': 'Nova Sonic (Real AWS)',
            'status': 'active',
            'model_id': self.model_id,
            'region': self.region,
            'active_sessions': len([s for s in self.sessions.values() if s.get('is_active', False)]),
            'total_sessions': len(self.sessions)
        }

    def get_available_voices(self) -> List[Dict[str, str]]:
        """Get available Nova Sonic voices"""
        return [
            {
                'id': 'nova-sonic-male-us',
                'name': 'Nova Sonic Male (US)',
                'language': 'en-US',
                'gender': 'male'
            },
            {
                'id': 'nova-sonic-female-us',
                'name': 'Nova Sonic Female (US)',
                'language': 'en-US',
                'gender': 'female'
            },
            {
                'id': 'nova-sonic-male-uk',
                'name': 'Nova Sonic Male (UK)',
                'language': 'en-GB',
                'gender': 'male'
            },
            {
                'id': 'nova-sonic-female-uk',
                'name': 'Nova Sonic Female (UK)',
                'language': 'en-GB',
                'gender': 'female'
            }
        ]

    def get_sales_scenarios(self) -> List[Dict[str, str]]:
        """Get available sales training scenarios for Nova Sonic"""
        return [
            {
                'id': 'cold_calling',
                'name': 'Cold Calling Practice',
                'description': 'Practice making initial contact with potential customers using Nova Sonic voice interaction'
            },
            {
                'id': 'objection_handling',
                'name': 'Objection Handling',
                'description': 'Learn to handle customer objections with Nova Sonic role-playing scenarios'
            },
            {
                'id': 'product_demo',
                'name': 'Product Demonstration',
                'description': 'Practice presenting products effectively with Nova Sonic feedback'
            },
            {
                'id': 'closing_techniques',
                'name': 'Closing Techniques',
                'description': 'Master various closing strategies with Nova Sonic conversation practice'
            },
            {
                'id': 'customer_discovery',
                'name': 'Customer Discovery',
                'description': 'Develop questioning skills to understand customer needs with Nova Sonic'
            }
        ]

# Sales training tools for Nova Sonic
class NovaSonicSalesTrainingTools:
    """Sales training tools that work with Nova Sonic"""
    
    def __init__(self):
        self.scenarios = {
            "demo_call": {
                "id": "demo_call",
                "name": "Product Demo Call",
                "description": "Practice presenting your product with an AI prospect",
                "system_prompt": "You are a potential customer interested in learning about a new product or service. Ask thoughtful questions, show interest but also some healthy skepticism. Help the salesperson practice their presentation skills."
            },
            "objection_handling": {
                "id": "objection_handling", 
                "name": "Objection Handling",
                "description": "Practice handling common sales objections",
                "system_prompt": "You are a potential customer with specific concerns and objections about the product being presented. Raise realistic objections that salespeople commonly face."
            },
            "discovery_call": {
                "id": "discovery_call",
                "name": "Discovery Call",
                "description": "Practice discovery and needs assessment",
                "system_prompt": "You are a potential customer who needs to be guided to reveal your pain points and needs. Don't volunteer information easily - make the salesperson ask good discovery questions."
            }
        }
    
    def get_scenario(self, scenario_id):
        return self.scenarios.get(scenario_id, self.scenarios["demo_call"])
    
    def get_all_scenarios(self):
        return list(self.scenarios.values())

# Create service instances
nova_sonic_service = NovaSONICService()
sales_training_tools = NovaSonicSalesTrainingTools() 